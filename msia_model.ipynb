{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":106187,"status":"ok","timestamp":1712479833659,"user":{"displayName":"YI FONG CHEONG","userId":"09210408435291314172"},"user_tz":-480},"id":"QZhKbBPtGvmO","outputId":"057d9f19-c8bd-4a42-8d6c-ce25a361bf3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XGjsJoJmZibs"},"outputs":[],"source":["import pandas as pd\n","import joblib"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7288,"status":"ok","timestamp":1712479840942,"user":{"displayName":"YI FONG CHEONG","userId":"09210408435291314172"},"user_tz":-480},"id":"nsaJCIQNHIur","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0b0d9df-4cbd-4fcf-c14b-6c7b649b3941"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/538.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/538.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m532.5/538.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m538.2/538.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install shap -q"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18049,"status":"ok","timestamp":1712479859392,"user":{"displayName":"YI FONG CHEONG","userId":"09210408435291314172"},"user_tz":-480},"id":"oyGjBEvNzQtS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d8498b9-4464-4b1a-97f0-4e2b21c6264d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/275.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m204.8/275.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for LIME (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install LIME -q"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":31269,"status":"ok","timestamp":1712479890656,"user":{"displayName":"YI FONG CHEONG","userId":"09210408435291314172"},"user_tz":-480},"id":"TvEH_gQMJnY7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8416d164-7f84-4e14-c747-bd6a32eb3ccf"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install --upgrade matplotlib -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9daXDyrLrKT"},"outputs":[],"source":["# %matplotlib inline\n","# %matplotlib notebook\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import balanced_accuracy_score, roc_auc_score, f1_score, roc_curve, precision_score, recall_score, accuracy_score\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.model_selection import StratifiedGroupKFold\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.linear_model import LogisticRegression\n","# import shap\n","# shap.initjs()\n","# import lime\n","# import lime.lime_tabular\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NOm4frSyLxvL"},"outputs":[],"source":["def convert_feature_to_label(df, col):\n","    le = LabelEncoder()\n","    df[col] = le.fit_transform(df[col])\n","    return df\n","\n","def convert_feature_to_one_hot(df, col):\n","    le = LabelEncoder()\n","    df[col] = le.fit_transform(df[col])\n","    oh = OneHotEncoder(handle_unknown='ignore')\n","    df_oh = pd.DataFrame(oh.fit_transform(df[[col]]).toarray())\n","    df = df.join(df_oh)\n","\n","    rename_dict = {}\n","\n","    for i, name in zip(df_oh.columns, le.classes_):\n","        rename_dict[i] = str(col) + '_' + str(name)\n","\n","    df = df.rename(columns=rename_dict)\n","    df.drop(col, axis = 1, inplace = True)\n","\n","    return df\n","\n","def scale_feature(col, method='std'):\n","    if method == 'std':\n","        std = np.std(col)\n","        mean = np.mean(col)\n","        return (col - mean) / std, mean, std\n","    elif method =='minmax':\n","        min = np.min(col)\n","        max = np.max(col)\n","        return (col - min) / max\n","\n","def calc_metrics(y_true, y_pred, metrics=[]):\n","    out = []\n","    #y_pred = y_pred >= 0.8357\n","    for met in metrics:\n","        if not met == roc_auc_score:\n","            out.append(met(y_true, y_pred.argmax(1)))\n","        else:\n","            out.append(met(y_true, np.max(y_pred, 1)))\n","\n","    return out\n","\n","def calc_class_weights(df, target='sga', type='log'):\n","    if type == 'log':\n","        valid_class = df[target].value_counts().sort_index().values\n","        # 1 / (1+ln(x))\n","        class_weights = 1./np.log1p(valid_class)\n","        # Normalize class_weights and multiply with number of classes\n","        class_weights = class_weights / class_weights.sum() * 2\n","\n","    elif type == 'normal':\n","        classes = df[target].value_counts().sort_index().values\n","        class_weights = classes/df.shape[0]\n","        class_weights = 1 - class_weights\n","        class_weights = class_weights / class_weights.sum() * 2\n","\n","    else:\n","        class_weights = None\n","\n","    return class_weights\n","\n","def ohe(df):\n","    # OHE for categorical data\n","    #for col in ['cord', 'presentation', 'placenta_site', 'hypertension', 'diabetes']:\n","    for col in ['hypertension', 'diabetes']:\n","        df = convert_feature_to_one_hot(df, col)\n","    for col in ['gender', 'smoking']:\n","        df = convert_feature_to_label(df, col)\n","\n","    # OHE for ordinal data\n","    df = df.replace({'oligohydramnios' : 0, 'normal' : 1, 'polyhydramnios' : 2})\n","    return df\n","\n","def ohe_tri3(df):\n","    # OHE for categorical data\n","    for col in ['presentation', 'placenta_site', 'hypertension', 'diabetes']:\n","        df = convert_feature_to_one_hot(df, col)\n","    for col in ['gender', 'smoking']:\n","        df = convert_feature_to_label(df, col)\n","\n","    # OHE for ordinal data\n","    df = df.replace({'oligohydramnios' : 0, 'normal' : 1, 'polyhydramnios' : 2})\n","    return df\n","\n","def data_impute(df):\n","    # Iterative data imputation\n","    imputer = IterativeImputer(random_state = 123)\n","    imputed = imputer.fit_transform(df)\n","    return pd.DataFrame(imputed, columns = df.columns)\n","\n","def sgkf(df, label = 'sga'):\n","    sgkf = StratifiedGroupKFold(shuffle=True, random_state=123, n_splits = 5)\n","\n","    df['fold'] = -1\n","\n","    for fold_num, (_, val_idx) in enumerate(sgkf.split(df, df[label], groups=df.id)):\n","        df.loc[val_idx, 'fold'] = fold_num\n","\n","    # tri2[tri2['fold'] == 0].sga.value_counts()\n","    return df.drop('id', axis=1)"]},{"cell_type":"markdown","metadata":{"id":"353_yUrXY3px"},"source":["# Tri3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":455,"status":"error","timestamp":1712480480579,"user":{"displayName":"YI FONG CHEONG","userId":"09210408435291314172"},"user_tz":-480},"id":"Mu5inx_5MDqi","outputId":"92589274-1068-4ff8-8cec-84176acae29f"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/cyf_clean_tri3.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-b83b6ee279db>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mtri3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/cyf_clean_tri3.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mtri3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lbw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sga'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#continuous_col = ['ac', 'bpd', 'efw_centile', 'efw', 'fl', 'ga', 'hc', 'mother_age_at_start_date', 'mother_height', 'mother_weight']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/cyf_clean_tri3.csv'"]}],"source":["def lr(df, label = 'sga'):\n","\n","    train_cols = df.columns\n","    train_cols = train_cols.drop([label, 'fold'])\n","\n","    oof_acc = []\n","    oof_roc_auc = []\n","    oof_f1 = []\n","    oof_prec = []\n","    oof_rec = []\n","    oof_thresh = []\n","    temp = None\n","\n","    #class_weights = calc_class_weights(df, target= label, type='normal')\n","\n","    for fold in range(5):\n","        #rfc = RandomForestClassifier(n_estimators = 56, criterion = 'log_loss', max_depth = 3, min_samples_split = 0.27, min_samples_leaf = 8, bootstrap = False, ccp_alpha = 0.05, max_features = None, min_impurity_decrease = 0.0332, random_state = 123)\n","        rfc = RandomForestClassifier(max_features = None, bootstrap = False, n_estimators = 1, max_depth = 1, criterion = \"entropy\", min_impurity_decrease = 0.1, verbose = 0, random_state = 123, min_samples_leaf = 1, ccp_alpha = 0.2)\n","        ros = RandomOverSampler(random_state = 196)\n","        train_df = df[df['fold'] != fold].reset_index(drop=True)\n","        train_X, train_Y = ros.fit_resample(train_df[train_cols], train_df[label])\n","        val_df = df[df['fold'] == fold].reset_index(drop=True)\n","\n","        #sample_weights = [class_weights[int(x)] for x in train_Y]\n","\n","        rfc.fit(train_X, train_Y)\n","\n","        out = rfc.predict_proba(val_df[train_cols])\n","        acc, roc_auc, f1, prec, rec = calc_metrics(val_df[label], out, metrics=[balanced_accuracy_score, roc_auc_score, f1_score, precision_score, recall_score])\n","        out2 = rfc.predict(val_df[train_cols])\n","\n","        oof_acc.append(acc)\n","        oof_roc_auc.append(roc_auc)\n","        oof_f1.append(f1)\n","        oof_prec.append(prec)\n","        oof_rec.append(rec)\n","\n","        print(\"********************\")\n","        print(f\"Fold: {fold}\")\n","        print(f\"Balanced Accuracy: {acc:.4f}\")\n","        print(f\"ROC AUC: {roc_auc:.4f}\")\n","        print(f\"F1: {f1:.4f}\")\n","        print(f\"Precision: {prec:.4f}\")\n","        print(f\"Recall: {rec:.4f}\")\n","        joblib.dump(rfc, f'tri3_rfc_fold_{fold}.joblib')\n","\n","        if fold == 2:\n","          print(val_df[train_cols].columns)\n","          val_df.to_csv(\"/content/tri3_df_fold_2.csv\")\n","\n","\n","\n","    print(f'OOF Balanced Accuracy: {np.mean(oof_acc):.4f} (±{np.std(oof_acc):.4f})')\n","    print(f'OOF ROC AUC Score: {np.mean(oof_roc_auc):.4f} (±{np.std(oof_roc_auc):.4f})')\n","    print(f'OOF F1 Score: {np.mean(oof_f1):.4f} (±{np.std(oof_f1):.4f})')\n","    print(f'OOF Prec Score: {np.mean(oof_prec):.4f} (±{np.std(oof_prec):.4f})')\n","    print(f'OOF Recall Score: {np.mean(oof_rec):.4f} (±{np.std(oof_rec):.4f})')\n","    return temp\n","\n","\n","tri3 = pd.read_csv('/content/cyf_clean_tri3.csv')\n","tri3.drop(['lbw', 'sga'], axis = 1, inplace = True)\n","#continuous_col = ['ac', 'bpd', 'efw_centile', 'efw', 'fl', 'ga', 'hc', 'mother_age_at_start_date', 'mother_height', 'mother_weight']\n","#tri3[continuous_col] = scale_feature(tri3[continuous_col], method='std')\n","#tri3 = tri3[['ac', 'af', 'bpd', 'efw_centile', 'efw', 'fl', 'ga', 'hc', 'mother_age_at_start_date', 'mother_height', 'mother_weight', 'smoking', 'gender', 'presentation', 'placenta_site', 'hypertension', 'diabetes']]\n","tri3 = ohe_tri3(tri3)\n","tri3 = data_impute(tri3)\n","tri3 = sgkf(tri3, label = 'status_change')\n","lr(tri3, label = 'status_change')\n"]},{"cell_type":"markdown","metadata":{"id":"_o-uqFd0Y1Qr"},"source":["# Tri2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2731,"status":"ok","timestamp":1712480495405,"user":{"displayName":"YI FONG CHEONG","userId":"09210408435291314172"},"user_tz":-480},"id":"a_vjjkQP_VXA","outputId":"1a5a2d54-ab70-4c12-9075-cf98fa66e423"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 602 entries, 0 to 601\n","Data columns (total 22 columns):\n"," #   Column                    Non-Null Count  Dtype  \n","---  ------                    --------------  -----  \n"," 0   ac                        602 non-null    float64\n"," 1   bpd                       602 non-null    float64\n"," 2   efw_centile               602 non-null    float64\n"," 3   efw                       602 non-null    float64\n"," 4   fl                        602 non-null    float64\n"," 5   ga                        602 non-null    float64\n"," 6   hc                        602 non-null    float64\n"," 7   mother_age_at_start_date  602 non-null    float64\n"," 8   mother_height             602 non-null    float64\n"," 9   mother_weight             602 non-null    float64\n"," 10  smoking                   602 non-null    float64\n"," 11  gender                    602 non-null    float64\n"," 12  status_change             602 non-null    float64\n"," 13  sga                       602 non-null    float64\n"," 14  cur_sga                   602 non-null    float64\n"," 15  hypertension_0.0          602 non-null    float64\n"," 16  hypertension_1.0          602 non-null    float64\n"," 17  hypertension_2.0          602 non-null    float64\n"," 18  diabetes_0.0              602 non-null    float64\n"," 19  diabetes_1.0              602 non-null    float64\n"," 20  diabetes_2.0              602 non-null    float64\n"," 21  fold                      602 non-null    int64  \n","dtypes: float64(21), int64(1)\n","memory usage: 103.6 KB\n","[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0\n"," 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0\n"," 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n"," 0 0]\n","********************\n","Fold: 0\n","Balanced Accuracy: 0.9646\n","ROC AUC: 0.8992\n","F1: 0.8824\n","Precision: 1.0000\n","Recall: 0.7895\n","Real SGA Balanced Accuracy: 0.8673\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n"," 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n"," 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n"," 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n","********************\n","Fold: 1\n","Balanced Accuracy: 0.9453\n","ROC AUC: 0.8937\n","F1: 0.8000\n","Precision: 0.7778\n","Recall: 0.8235\n","Real SGA Balanced Accuracy: 0.8594\n","[0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n"," 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 1 0 0 0 1 1]\n","********************\n","Fold: 2\n","Balanced Accuracy: 0.8240\n","ROC AUC: 0.6250\n","F1: 0.3889\n","Precision: 0.2917\n","Recall: 0.5833\n","Real SGA Balanced Accuracy: 0.8080\n","[0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0\n"," 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0\n"," 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n"," 0 0 1 0 0 0 0 0 0]\n","********************\n","Fold: 3\n","Balanced Accuracy: 0.8583\n","ROC AUC: 0.5450\n","F1: 0.6222\n","Precision: 0.7778\n","Recall: 0.5185\n","Real SGA Balanced Accuracy: 0.8500\n","[0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1\n"," 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n"," 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n"," 0 0 0 0 0]\n","********************\n","Fold: 4\n","Balanced Accuracy: 0.7759\n","ROC AUC: 0.6190\n","F1: 0.4348\n","Precision: 0.3125\n","Recall: 0.7143\n","Real SGA Balanced Accuracy: 0.7241\n","OOF Balanced Accuracy: 0.8736 (±0.0717)\n","OOF ROC AUC Score: 0.7164 (±0.1497)\n","OOF F1 Score: 0.6256 (±0.1943)\n","OOF Prec Score: 0.6319 (±0.2814)\n","OOF Recall Score: 0.6858 (±0.1175)\n"]}],"source":["def rf(df, label = 'sga'):\n","\n","    train_cols = df.columns\n","    train_cols = train_cols.drop([label, 'fold', 'cur_sga', 'sga'])\n","\n","    oof_acc = []\n","    oof_roc_auc = []\n","    oof_f1 = []\n","    oof_prec = []\n","    oof_rec = []\n","    oof_thresh = []\n","    temp = None\n","\n","    class_weights = calc_class_weights(df, target= label, type='normal')\n","\n","\n","\n","    for fold in range(5):\n","\n","      ros = RandomOverSampler(random_state = 317)\n","      rfc = RandomForestClassifier(n_estimators = 56, criterion = 'log_loss', max_depth = 3, min_samples_split = 0.27, min_samples_leaf = 8, bootstrap = False, ccp_alpha = 0.05, max_features = None, min_impurity_decrease = 0.0332, random_state = 123)\n","      train_df = df[df['fold'] != fold].reset_index(drop=True)\n","      train_X, train_Y = ros.fit_resample(train_df[train_cols], train_df[label])\n","      val_df = df[df['fold'] == fold].reset_index(drop=True)\n","      tmp = val_df[['sga', 'cur_sga', label]]\n","      val_df = val_df.drop(['sga', 'cur_sga'], axis=1)\n","      sample_weights = [class_weights[int(x)] for x in train_Y]\n","\n","      rfc.fit(train_X, train_Y)\n","\n","      out = rfc.predict_proba(val_df[train_cols])\n","      acc, roc_auc, f1, prec, rec = calc_metrics(val_df[label], out, metrics=[accuracy_score, roc_auc_score, f1_score, precision_score, recall_score])\n","      out2 = rfc.predict_proba(val_df[train_cols])\n","      out2 = out2.argmax(1)\n","      # print(out2)\n","      cur_sga = tmp['sga']\n","      # cur_sga2 = np.logical_xor(tmp[label], tmp['sga']).astype(int)\n","      # check = all(np.logical_not(np.logical_xor(cur_sga, cur_sga2)).astype(int))\n","      # print(check)\n","      out2 = np.logical_xor(out2, cur_sga.to_numpy())\n","      print(out2.astype(int))\n","\n","      oof_acc.append(acc)\n","      oof_roc_auc.append(roc_auc)\n","      oof_f1.append(f1)\n","      oof_prec.append(prec)\n","      oof_rec.append(rec)\n","      joblib.dump(rfc, f'tri2_rfc_fold_{fold}.joblib')\n","\n","      print(\"********************\")\n","      print(f\"Fold: {fold}\")\n","      print(f\"Balanced Accuracy: {acc:.4f}\")\n","      print(f\"ROC AUC: {roc_auc:.4f}\")\n","      print(f\"F1: {f1:.4f}\")\n","      print(f\"Precision: {prec:.4f}\")\n","      print(f\"Recall: {rec:.4f}\")\n","      print(f\"Real SGA Balanced Accuracy: {accuracy_score(out2, tmp['sga']):.4f}\")\n","      if fold == 0:\n","          val_df['sga'] = tmp['sga']\n","          val_df['cur_sga'] = tmp['cur_sga']\n","          val_df['pred_status_change'] = out.argmax(1)\n","          val_df['pred_sga'] = out2\n","          val_df.to_csv(\"/content/tri2_df_fold_0.csv\")\n","\n","\n","    # 1. Print accuracy of 5 folds\n","    # 2. Save cross validation data and test on dashboard\n","    # 3.\n","\n","    # Calculate SHAP values after training on all folds\n","    # (you may want to use a subset of your data for better runtime)\n","    # shap_explainer = shap.TreeExplainer(rf)\n","    # all_data = df[train_cols]  # or use a subset if your dataset is large\n","    # shap_values = shap_explainer.shap_values(all_data)\n","\n","    # # Choose an instance for which you want to generate SHAP force plot\n","    # instance_idx = 0  # Choose the index of the instance\n","\n","    # %matplotlib inline\n","    # # Generate SHAP force plot\n","    # shap.force_plot(\n","    #     shap_explainer.expected_value[1],  # Shap values for the positive class\n","    #     shap_values[1][instance_idx, :],\n","    #     features=all_data.iloc[instance_idx, :],\n","    #     feature_names=train_cols\n","    # )\n","\n","    # plt.show()\n","\n","    # # Use SHAP values for interpretation or visualization\n","    # # For example, you can print a summary plot\n","    #shap.summary_plot(shap_values[1], features=all_data, feature_names=train_cols)\n","    # #shap.plots.waterfall(shap_values)\n","\n","    # Calculate LIME explanations after training on all folds\n","    # explainer = lime.lime_tabular.LimeTabularExplainer(\n","    #     training_data=train_X.values,  # Use training data for explanation\n","    #     mode='classification',\n","    #     feature_names=train_cols,\n","    #     class_names=['Not Positive', 'Positive'],\n","    #     discretize_continuous=True  # Set to False if your data is not continuous\n","    # )\n","\n","    # # Choose an instance for which you want to explain the prediction\n","    # instance_idx = 10  # Choose the index of the instance you want to explain\n","    # instance = val_df[train_cols].iloc[[instance_idx]].values\n","\n","    # # Get a LIME explanation for the Random Forest prediction\n","    # lime_explanation = explainer.explain_instance(\n","    #     instance[0],\n","    #     rf.predict_proba,\n","    #     num_features=len(train_cols),\n","    #     top_labels=1,\n","    # )\n","\n","    # # Display the LIME explanation\n","    # lime_explanation.show_in_notebook()\n","\n","    # #plt = lime_explanation.as_pyplot_figure()\n","\n","    print(f'OOF Balanced Accuracy: {np.mean(oof_acc):.4f} (±{np.std(oof_acc):.4f})')\n","    print(f'OOF ROC AUC Score: {np.mean(oof_roc_auc):.4f} (±{np.std(oof_roc_auc):.4f})')\n","    print(f'OOF F1 Score: {np.mean(oof_f1):.4f} (±{np.std(oof_f1):.4f})')\n","    print(f'OOF Prec Score: {np.mean(oof_prec):.4f} (±{np.std(oof_prec):.4f})')\n","    print(f'OOF Recall Score: {np.mean(oof_rec):.4f} (±{np.std(oof_rec):.4f})')\n","\n","    # joblib.dump(rfc, '/content/drive/MyDrive/SGA/withBiomarker/trained_model.pkl')\n","\n","    return temp\n","\n","\n","# tri2 = pd.read_csv('/content/drive/MyDrive/SGA/cyf_clean_tri2.csv')\n","tri2 = pd.read_csv('/content/drive/MyDrive/SGA/cyf_clean_tri2.csv')\n","# tri2.drop(['sga', 'lbw', 'cur_sga'], axis = 1, inplace = True)\n","continuous_col = ['ac', 'bpd', 'cm', 'efw_centile', 'efw', 'fl', 'ga', 'hc', 'hl', 'tcd', 'mother_age_at_start_date', 'mother_height', 'mother_weight']\n","ori_tri2 = tri2.copy()\n","# for c in continuous_col:\n","#   tri2[c], _, _ = scale_feature(tri2[c], method='std')\n","\n","# means.to_csv(\"tri2_means.csv\")\n","# stds.to_csv(\"tri2_stds.csv\")\n","tri2 = tri2[['ac', 'bpd', 'efw_centile', 'efw', 'fl', 'ga', 'hc', 'mother_age_at_start_date', 'mother_height', 'mother_weight', 'smoking', 'gender', 'hypertension', 'diabetes', 'status_change', 'id', 'sga', 'cur_sga']]\n","tri2 = ohe(tri2)\n","tri2 = data_impute(tri2)\n","tri2 = sgkf(tri2, label = 'status_change')\n","tri2.info()\n","rf(tri2, label = 'status_change')\n","# joblib.dump(rf, 'tri2_rf.joblib')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FFZTzZZlXUQN"},"outputs":[],"source":["plt.hist(tri2['bpd'])\n","plt.hist(ori_tri2['bpd'])\n","\n","tmp = (ori_tri2['bpd'] - np.mean(ori_tri2['bpd'])) / np.std(ori_tri2['bpd'])\n","plt.hist(tmp)\n","print(tmp.min(), tmp.max())\n","print(tri2['bpd'].min(), tri2['bpd'].max())\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1OB5DLXZVVc"},"outputs":[],"source":["test = pd.read_csv('/content/drive/MyDrive/SGA/withBiomarker/with_biomarker_test_data.csv', usecols=lambda column: column != 'Unnamed: 0')\n","test.drop(['sga', 'lbw', '2_cur_sga', 'diabetes', 'hypertension'], axis = 1, inplace = True)\n","continuous_col = ['2_ac', '2_bpd', '2_efw_centile', '2_efw', '2_fl', '2_ga', '2_hc', '1_m_age', '1_m_height', '1_m_weight']\n","test[continuous_col] = scale_feature(test[continuous_col], method='std')\n","test['sc'] = test['sc'].astype(int)\n","test.rename(columns = {'2_ac' : 'ac',\n","                        '2_bpd' : 'bpd',\n","                        '2_efw_centile' : 'efw_centile',\n","                        '2_efw' : 'efw',\n","                        '2_fl' : 'fl',\n","                        '2_ga' : 'ga',\n","                        '2_hc' : 'hc',\n","                        '1_m_age' : 'mother_age_at_start_date',\n","                        '1_m_height' : 'mother_height',\n","                        '1_m_weight' : 'mother_weight',\n","                        'sc' : 'status_change'}, inplace = True)\n","test['diabetes_0.0'] = 0\n","test['diabetes_1.0'] = 0\n","test['diabetes_2.0'] = 0\n","test['hypertension_0.0'] = 0\n","test['hypertension_1.0'] = 0\n","test['hypertension_2.0'] = 0\n","test['smoking'] = 0\n","test = test[['ac', 'bpd', 'efw_centile', 'efw', 'fl', 'ga', 'hc', 'mother_age_at_start_date', 'mother_height', 'mother_weight', 'smoking', 'status_change', 'gender', 'hypertension_0.0', 'hypertension_1.0', 'hypertension_2.0', 'diabetes_0.0', 'diabetes_1.0', 'diabetes_2.0']]\n","test.info()"]},{"cell_type":"markdown","metadata":{"id":"ASKW21P2lI5c"},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c-HTxJn7hCKD"},"outputs":[],"source":["trained_model = joblib.load('/content/drive/MyDrive/SGA/withBiomarker/trained_model.pkl')\n","X_test = test.drop('status_change', axis = 1)  # Assuming 'sc' is the target variable\n","y_true = test['status_change']\n","predictions = trained_model.predict(X_test)\n","balanced_accuracy = balanced_accuracy_score(y_true, predictions)\n","precision = precision_score(y_true, predictions)\n","recall = recall_score(y_true, predictions)\n","f1 = f1_score(y_true, predictions)\n","roc_auc = roc_auc_score(y_true, predictions)\n","test['prediction'] = predictions\n","test['status_change'] = y_true\n","\n","# Print or display the evaluation results\n","print(f'Accuracy: {balanced_accuracy:.2f}')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1-score: {f1:.2f}')\n","print(f'ROC AUC: {roc_auc:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6JOgHGxCyxTY"},"outputs":[],"source":["test.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohjPP1rwzTZo"},"outputs":[],"source":["test.to_csv('/content/drive/MyDrive/SGA/withBiomarker/result_of_test_data_on_trained_model.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uNF43_s6mPfL"},"outputs":[],"source":["# def rf(df, label = 'sga'):\n","\n","#     train_cols = df.columns\n","#     train_cols = train_cols.drop([label, 'fold'])\n","\n","#     oof_acc = []\n","#     oof_roc_auc = []\n","#     oof_f1 = []\n","#     oof_prec = []\n","#     oof_rec = []\n","#     oof_thresh = []\n","#     temp = None\n","\n","#     class_weights = calc_class_weights(df, target= label, type='normal')\n","\n","#     rf = LogisticRegression(class_weight = 'balanced')\n","\n","#     for fold in range(5):\n","\n","#       ros = RandomOverSampler(random_state = 317)\n","\n","#       train_df = df[df['fold'] != fold].reset_index(drop=True)\n","#       train_X, train_Y = ros.fit_resample(train_df[train_cols], train_df[label])\n","#       val_df = df[df['fold'] == fold].reset_index(drop=True)\n","#       sample_weights = [class_weights[int(x)] for x in train_Y]\n","\n","#       rf.fit(train_X, train_Y)\n","\n","#       out = rf.predict_proba(val_df[train_cols])\n","#       acc, roc_auc, f1, prec, rec = calc_metrics(val_df[label], out, metrics=[balanced_accuracy_score, roc_auc_score, f1_score, precision_score, recall_score])\n","#       out2 = rf.predict(val_df[train_cols])\n","\n","#       oof_acc.append(acc)\n","#       oof_roc_auc.append(roc_auc)\n","#       oof_f1.append(f1)\n","#       oof_prec.append(prec)\n","#       oof_rec.append(rec)\n","\n","#     # Calculate SHAP values after training on all folds\n","#     # (you may want to use a subset of your data for better runtime)\n","#     # shap_explainer = shap.TreeExplainer(rf)\n","#     # all_data = df[train_cols]  # or use a subset if your dataset is large\n","#     # shap_values = shap_explainer.shap_values(all_data)\n","\n","#     # # Choose an instance for which you want to generate SHAP force plot\n","#     # instance_idx = 0  # Choose the index of the instance\n","\n","#     # %matplotlib inline\n","#     # # Generate SHAP force plot\n","#     # shap.force_plot(\n","#     #     shap_explainer.expected_value[1],  # Shap values for the positive class\n","#     #     shap_values[1][instance_idx, :],\n","#     #     features=all_data.iloc[instance_idx, :],\n","#     #     feature_names=train_cols\n","#     # )\n","\n","#     # plt.show()\n","\n","#     # # Use SHAP values for interpretation or visualization\n","#     # # For example, you can print a summary plot\n","#     #shap.summary_plot(shap_values[1], features=all_data, feature_names=train_cols)\n","#     # #shap.plots.waterfall(shap_values)\n","\n","#     # Calculate LIME explanations after training on all folds\n","#     # explainer = lime.lime_tabular.LimeTabularExplainer(\n","#     #     training_data=train_X.values,  # Use training data for explanation\n","#     #     mode='classification',\n","#     #     feature_names=train_cols,\n","#     #     class_names=['Not Positive', 'Positive'],\n","#     #     discretize_continuous=True  # Set to False if your data is not continuous\n","#     # )\n","\n","#     # # Choose an instance for which you want to explain the prediction\n","#     # instance_idx = 10  # Choose the index of the instance you want to explain\n","#     # instance = val_df[train_cols].iloc[[instance_idx]].values\n","\n","#     # # Get a LIME explanation for the Random Forest prediction\n","#     # lime_explanation = explainer.explain_instance(\n","#     #     instance[0],\n","#     #     rf.predict_proba,\n","#     #     num_features=len(train_cols),\n","#     #     top_labels=1,\n","#     # )\n","\n","#     # # Display the LIME explanation\n","#     # lime_explanation.show_in_notebook()\n","\n","#     # #plt = lime_explanation.as_pyplot_figure()\n","\n","#     print(f'OOF Balanced Accuracy: {np.mean(oof_acc):.4f} (±{np.std(oof_acc):.4f})')\n","#     print(f'OOF ROC AUC Score: {np.mean(oof_roc_auc):.4f} (±{np.std(oof_roc_auc):.4f})')\n","#     print(f'OOF F1 Score: {np.mean(oof_f1):.4f} (±{np.std(oof_f1):.4f})')\n","#     print(f'OOF Prec Score: {np.mean(oof_prec):.4f} (±{np.std(oof_prec):.4f})')\n","#     print(f'OOF Recall Score: {np.mean(oof_rec):.4f} (±{np.std(oof_rec):.4f})')\n","\n","#     return temp\n","\n","\n","# tri2 = pd.read_csv('/content/drive/MyDrive/SGA/cyf_clean_tri2.csv')\n","# tri2.drop(['sga', 'lbw', 'cur_sga'], axis = 1, inplace = True)\n","# continuous_col = ['ac', 'bpd', 'cm', 'efw_centile', 'efw', 'fl', 'ga', 'hc', 'hl', 'tcd', 'mother_age_at_start_date', 'mother_height', 'mother_weight']\n","# tri2[continuous_col] = scale_feature(tri2[continuous_col], method='std')\n","# tri2 = tri2[['ac', 'bpd', 'efw_centile', 'efw', 'fl', 'ga', 'hc', 'mother_age_at_start_date', 'mother_height', 'mother_weight', 'smoking', 'gender', 'hypertension', 'diabetes', 'status_change', 'id']]\n","# tri2 = ohe(tri2)\n","# tri2 = data_impute(tri2)\n","# tri2 = sgkf(tri2, label = 'status_change')\n","# rf(tri2, label = 'status_change')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gR5ekgFbgy31"},"outputs":[],"source":["tri2 = pd.read_csv('/content/drive/MyDrive/SGA/cyf_clean_tri2.csv')\n","tri2.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jWCZK383bbiJ"},"outputs":[],"source":["import random\n","import math\n","import numpy as np\n","cur_sga = np.array([random.randint(0, 1) for _ in range(10)])\n","sga = np.array([random.randint(0, 1) for _ in range(10)])\n","pred_sc = np.array([random.randint(0, 1) for _ in range(10)])\n","sc = np.logical_xor(cur_sga, sga).astype(int)\n","correct_sc = np.logical_not(np.logical_xor(pred_sc, sc)).astype(int)\n","pred_sga = np.logical_xor(pred_sc, cur_sga).astype(int)\n","correct_sga = np.logical_not(np.logical_xor(pred_sga, sga)).astype(int)\n","print(cur_sga)\n","print(sga)\n","print(pred_sc)\n","print(sc)\n","print(correct_sc)\n","print(pred_sga)\n","print(correct_sga)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"InSG4JVrztwN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713360073886,"user_tz":-480,"elapsed":392,"user":{"displayName":"YI FONG CHEONG","userId":"09210408435291314172"}},"outputId":"38b900eb-1795-46b9-818f-bc28a81bc97d"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.9646017699115044\n","0.9646017699115044\n"]}],"source":["import numpy as np\n","from sklearn.metrics import accuracy_score, balanced_accuracy_score\n","cur_sga = '''0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0'''\n","cur_sga = np.array(cur_sga.split('. ')).astype(int)\n","\n","sga = '''0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0'''\n","sga = np.array(sga.split('. ')).astype(int)\n","sc = np.logical_xor(cur_sga, sga)\n","ref_sc = '''0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0'''\n","ref_sc = np.array(ref_sc.split('. ')).astype(int)\n","pred_sc = '''0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  1  1  0  0  0  0  0  0  1  0  1  0  1  0  0  0  0  1  1  0  0  0  0  0  1  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0'''\n","pred_sc = np.array(pred_sc.split('  ')).astype(int)\n","correct_sc = np.logical_not(np.logical_xor(pred_sc, sc)).astype(int)\n","pred_sga = np.logical_xor(pred_sc, cur_sga).astype(int)\n","#print(balanced_accuracy_score(pred_sc, sc))\n","print(accuracy_score(pred_sc, sc))\n","print(accuracy_score(pred_sga, sga))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}